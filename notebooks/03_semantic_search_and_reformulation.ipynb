{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac7b7841",
   "metadata": {},
   "source": [
    "# 03 â€” Semantic Search & Reformulation\n",
    "\n",
    "**Objective.**\n",
    "- Embed FAQ entries, compute similarity against a user query.\n",
    "- Use LLM router: prefer local Ollama if available, else Hugging Face fallback.\n",
    "- Return top-k with confidence.\n",
    "\n",
    "**Notes.** Keep everything lightweight and reproducible, no external secrets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357796a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, pathlib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "ROOT = pathlib.Path(__file__).resolve().parents[1]\n",
    "DATA = ROOT / \"data\"\n",
    "faq = json.loads((DATA / \"faq_dataset.json\").read_text(encoding=\"utf-8\"))\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "texts = [f\"{x['question']} {x['answer']}\" for x in faq]\n",
    "emb = model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "def topk(query: str, k: int = 3):\n",
    "    qv = model.encode([query], convert_to_numpy=True)\n",
    "    sims = cosine_similarity(qv, emb).ravel()\n",
    "    idx = np.argsort(-sims)[:k]\n",
    "    return [(faq[i], float(sims[i])) for i in idx]\n",
    "\n",
    "topk(\"how to reserve a book?\", k=3)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
